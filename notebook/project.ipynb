{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cb8508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3bc85bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('spam_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "41e980e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?? the secrets to SUCCESS</td>\n",
       "      <td>Hi James,\\n\\nHave you claim your complimentary...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>?? You Earned 500 GCLoot Points</td>\n",
       "      <td>\\nalt_text\\nCongratulations, you just earned\\n...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?? Your GitHub launch code</td>\n",
       "      <td>Here's your GitHub launch code, @Mortyj420!\\n ...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The Virtual Reward Center] Re: ** Clarifications</td>\n",
       "      <td>Hello,\\n \\nThank you for contacting the Virtua...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1 MLB Expert Inside, Plus Everything You Ne...</td>\n",
       "      <td>Hey Prachanda Rawal,\\n\\nToday's newsletter is ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                          ?? the secrets to SUCCESS   \n",
       "1                    ?? You Earned 500 GCLoot Points   \n",
       "2                         ?? Your GitHub launch code   \n",
       "3  [The Virtual Reward Center] Re: ** Clarifications   \n",
       "4  10-1 MLB Expert Inside, Plus Everything You Ne...   \n",
       "\n",
       "                                                text      type  \n",
       "0  Hi James,\\n\\nHave you claim your complimentary...      spam  \n",
       "1  \\nalt_text\\nCongratulations, you just earned\\n...  not spam  \n",
       "2  Here's your GitHub launch code, @Mortyj420!\\n ...  not spam  \n",
       "3  Hello,\\n \\nThank you for contacting the Virtua...  not spam  \n",
       "4  Hey Prachanda Rawal,\\n\\nToday's newsletter is ...      spam  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "266222f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 3)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dfc3d",
   "metadata": {},
   "source": [
    "## REMOVING SPECIAL CHARACTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5b4df474",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "916fbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for i in range(len(df['title'])):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['title'][i])  # Fixed regex: 'A-z' to 'A-Z'\n",
    "    review = review.lower()\n",
    "    words = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    titles.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f624a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5fe3ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(len(df['text'])):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])  # Fixed regex: 'A-z' to 'A-Z'\n",
    "    review = review.lower()\n",
    "    words = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    text.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2a15bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810cc00d",
   "metadata": {},
   "source": [
    "## Dependent and independent variables splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d99c611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "baa8359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ee083",
   "metadata": {},
   "source": [
    "## Encoding Dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "89dd7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(df['type']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f2194b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bb1ed",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "27f14146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe645ec",
   "metadata": {},
   "source": [
    "## Vectorization of Data using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fd14d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7bf5abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2756c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv_title = TfidfVectorizer(max_features=2500, ngram_range=(1,2))\n",
    "titles_train = tv_title.fit_transform(X_train['title']).toarray()\n",
    "titles_test = tv_title.transform(X_test['title']).toarray()\n",
    "\n",
    "tv_text = TfidfVectorizer(max_features=2500, ngram_range=(1,2))\n",
    "text_train = tv_text.fit_transform(X_train['text']).toarray()\n",
    "text_test = tv_text.transform(X_test['text']).toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3a4e565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = np.hstack([titles_train, text_train])\n",
    "combined_test = np.hstack([titles_test, text_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dfd91c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a26846f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e5fadd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5bf9459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baye=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "556d93ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baye.fit(combined_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fbf5059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2851)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a6ac1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ad31505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=baye.predict(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "42ecf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Libraries\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "89d6bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[ 2  7]\n",
      " [ 0 17]]\n",
      "Accuracy 0.7307692307692307\n",
      "Precision: 0.7083333333333334\n",
      "Recall: 1.0\n",
      "F1-Score: 0.8292682926829268\n",
      "ROC AUC: 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"Confusion Matrix:\",cm)\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0eac7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b2d45256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9655\n",
      "- F1 score: 0.9649\n",
      "- Precision: 0.9535\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9412\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6923\n",
      "- F1 score: 0.5985\n",
      "- Precision: 0.6800\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.5556\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6923\n",
      "- F1 score: 0.6816\n",
      "- Precision: 0.7368\n",
      "- Recall: 0.8235\n",
      "- Roc Auc Score: 0.6340\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7308\n",
      "- F1 score: 0.6681\n",
      "- Precision: 0.7083\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.6111\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6923\n",
      "- F1 score: 0.6816\n",
      "- Precision: 0.7368\n",
      "- Recall: 0.8235\n",
      "- Roc Auc Score: 0.6340\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6923\n",
      "- F1 score: 0.6816\n",
      "- Precision: 0.7368\n",
      "- Recall: 0.8235\n",
      "- Roc Auc Score: 0.6340\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9483\n",
      "- F1 score: 0.9487\n",
      "- Precision: 0.9750\n",
      "- Recall: 0.9512\n",
      "- Roc Auc Score: 0.9462\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7692\n",
      "- F1 score: 0.7736\n",
      "- Precision: 0.8667\n",
      "- Recall: 0.7647\n",
      "- Roc Auc Score: 0.7712\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive_bayes\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9828\n",
      "- F1 score: 0.9826\n",
      "- Precision: 0.9762\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9706\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7308\n",
      "- F1 score: 0.6681\n",
      "- Precision: 0.7083\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.6111\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logisitic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Gradient Boost\":GradientBoostingClassifier(),\n",
    "    \"Adaboost\":AdaBoostClassifier(),\n",
    "    \"Xgboost\":XGBClassifier(),\n",
    "    \"Naive_bayes\":MultinomialNB()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(combined_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(combined_train)\n",
    "    y_test_pred = model.predict(combined_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "546afb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter Training\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8, 12, 20, 30],\n",
    "                  \"n_estimators\": [100, 200, 300],\n",
    "                  \"colsample_bytree\": [0.5, 0.8, 1, 0.3, 0.4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e4666174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "randomcv_models = [\n",
    "                   (\"RF\", RandomForestClassifier(), rf_params),\n",
    "    (\"Xgboost\", XGBClassifier(), xgboost_params)\n",
    "                   \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "75b7931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Projects\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.68947368 0.68947368 0.68947368 0.68947368 0.68947368 0.68947368\n",
      " 0.70701754 0.68947368 0.68947368 0.68947368 0.70701754 0.70701754\n",
      "        nan        nan 0.68947368 0.70701754 0.67017544        nan\n",
      "        nan 0.56929825 0.68947368        nan 0.68947368 0.70614035\n",
      " 0.70701754 0.68947368 0.68947368        nan 0.70614035 0.68947368\n",
      " 0.63596491 0.70614035 0.70614035 0.70614035        nan 0.70701754\n",
      " 0.68947368 0.68947368 0.70701754 0.68947368 0.68947368 0.68947368\n",
      " 0.68947368 0.63596491 0.68947368 0.68947368 0.68947368 0.70614035\n",
      "        nan 0.68947368 0.70701754 0.68947368 0.68947368 0.70701754\n",
      " 0.68947368 0.68947368 0.68947368 0.70614035 0.68947368        nan\n",
      " 0.68947368        nan 0.68947368 0.68947368        nan 0.68947368\n",
      " 0.68947368 0.70614035 0.68947368        nan 0.68947368 0.70701754\n",
      " 0.68947368        nan 0.68947368        nan        nan        nan\n",
      "        nan        nan 0.68947368 0.68947368 0.68947368        nan\n",
      " 0.70701754        nan        nan 0.68947368 0.70614035 0.68947368\n",
      " 0.68947368        nan        nan 0.68947368 0.66929825 0.68947368\n",
      "        nan        nan 0.68947368 0.68947368]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "---------------- Best Params for RF -------------------\n",
      "{'n_estimators': 100, 'min_samples_split': 20, 'max_features': 5, 'max_depth': 10}\n",
      "---------------- Best Params for Xgboost -------------------\n",
      "{'n_estimators': 100, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(combined_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b8f0f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8793\n",
      "- F1 score: 0.8684\n",
      "- Precision: 0.8542\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.7941\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6923\n",
      "- F1 score: 0.5985\n",
      "- Precision: 0.6800\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.5556\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8103\n",
      "- F1 score: 0.7762\n",
      "- Precision: 0.7885\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.6765\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6154\n",
      "- F1 score: 0.5481\n",
      "- Precision: 0.6522\n",
      "- Recall: 0.8824\n",
      "- Roc Auc Score: 0.4967\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \n",
    "    \"Random Forest\":RandomForestClassifier(n_estimators=100,min_samples_split=20,\n",
    "                                          max_features=5,max_depth=10),\n",
    "    \"Xgboost\":XGBClassifier(n_estimators=100,max_depth=20,learning_rate=0.01,\n",
    "                           colsample_bytree=1)\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(combined_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(combined_train)\n",
    "    y_test_pred = model.predict(combined_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd7538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
